{"nbformat_minor": 1, "cells": [{"execution_count": 1, "cell_type": "code", "source": "from azureml import Workspace\n\nws = Workspace()\nds = ws.datasets['HSIN8 20180703-20180706 Hang Seng Futures.csv']\ndf = ds.to_dataframe()", "outputs": [], "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "import pandas as pd\nimport datetime\n\nfrom sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor", "outputs": [], "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "df['Date'] = pd.to_datetime(df['Date'],format='%d/%m/%Y')\ndf.drop(['Ticker','Date'], axis=1, inplace=True)\ndf.set_index('Time', inplace=True)\n\ndf.head()", "outputs": [{"execution_count": 3, "output_type": "execute_result", "data": {"text/plain": "          Open   High    Low  Close  Volume  Predict_close\nTime                                                      \n9:14:00  28388  28388  28308  28316    1789          28296\n9:15:00  28314  28351  28272  28296    1327          28278\n9:16:00  28287  28302  28265  28278     716          28294\n9:17:00  28265  28298  28265  28294     867          28312\n9:18:00  28292  28319  28292  28312     887          28315", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>Open<\/th>\n      <th>High<\/th>\n      <th>Low<\/th>\n      <th>Close<\/th>\n      <th>Volume<\/th>\n      <th>Predict_close<\/th>\n    <\/tr>\n    <tr>\n      <th>Time<\/th>\n      <th><\/th>\n      <th><\/th>\n      <th><\/th>\n      <th><\/th>\n      <th><\/th>\n      <th><\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>9:14:00<\/th>\n      <td>28388<\/td>\n      <td>28388<\/td>\n      <td>28308<\/td>\n      <td>28316<\/td>\n      <td>1789<\/td>\n      <td>28296<\/td>\n    <\/tr>\n    <tr>\n      <th>9:15:00<\/th>\n      <td>28314<\/td>\n      <td>28351<\/td>\n      <td>28272<\/td>\n      <td>28296<\/td>\n      <td>1327<\/td>\n      <td>28278<\/td>\n    <\/tr>\n    <tr>\n      <th>9:16:00<\/th>\n      <td>28287<\/td>\n      <td>28302<\/td>\n      <td>28265<\/td>\n      <td>28278<\/td>\n      <td>716<\/td>\n      <td>28294<\/td>\n    <\/tr>\n    <tr>\n      <th>9:17:00<\/th>\n      <td>28265<\/td>\n      <td>28298<\/td>\n      <td>28265<\/td>\n      <td>28294<\/td>\n      <td>867<\/td>\n      <td>28312<\/td>\n    <\/tr>\n    <tr>\n      <th>9:18:00<\/th>\n      <td>28292<\/td>\n      <td>28319<\/td>\n      <td>28292<\/td>\n      <td>28312<\/td>\n      <td>887<\/td>\n      <td>28315<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<\/div>"}, "metadata": {}}], "metadata": {}}, {"execution_count": 4, "cell_type": "code", "source": "y = df['Predict_close']\nX = df.drop(['Predict_close'], axis=1)", "outputs": [], "metadata": {}}, {"execution_count": 5, "cell_type": "code", "source": "#train:Test = 80:20\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size =0.80, test_size = 0.2, random_state=0)", "outputs": [], "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": "##########Regression##########\nlr = linear_model.LinearRegression()\nlr.fit(X_train , y_train)\n\nlr_train_scores = cross_val_score(lr, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\nlr_test_scores = cross_val_score(lr, X_test, y_test, scoring='neg_mean_squared_error', cv=10)\n\nprint('RMSE for Train set: %.2f' % abs(lr_train_scores.mean())**(1/2))\nprint('RMSE for Test set: %.2f' % abs(lr_test_scores.mean())**(1/2))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "RMSE for Train set: 20.20\nRMSE for Test set: 21.15\n"}], "metadata": {}}, {"execution_count": 7, "cell_type": "code", "source": "model_dict = {\n        'rf': (RandomForestRegressor(),{'bootstrap': [True], 'max_depth': [2, 3, 4], 'max_features': [2, 3, 4]}), \n        'gbdt': (GradientBoostingRegressor(),{'max_depth': [2, 3, 4, 5]}), \n        }\n\ndef test_classifier(clf,grid_values):\n    \n    grid_search = GridSearchCV(estimator = clf, param_grid = grid_values, cv = 10, scoring='neg_mean_squared_error')\n    grid_search.fit(X_train, y_train)\n    best_params = grid_search.best_params_\n    #best_score_ is the best score from the cross-validation\n    best_train_score = grid_search.best_score_\n\n    return (grid_search.best_estimator_, best_params, abs(best_train_score)**(1/2))\n\nfor model in model_dict:\n    print(test_classifier(model_dict[model][0],model_dict[model][1]),'\\n')", "outputs": [{"output_type": "stream", "name": "stdout", "text": "(GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n             max_leaf_nodes=None, min_impurity_split=1e-07,\n             min_samples_leaf=1, min_samples_split=2,\n             min_weight_fraction_leaf=0.0, n_estimators=100,\n             presort='auto', random_state=None, subsample=1.0, verbose=0,\n             warm_start=False), {'max_depth': 2}, 21.236371219784932) \n\n(RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=4,\n           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n           oob_score=False, random_state=None, verbose=0, warm_start=False), {'max_depth': 4, 'bootstrap': True, 'max_features': 4}, 22.103737797902713) \n\n"}], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.4.5", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}}
